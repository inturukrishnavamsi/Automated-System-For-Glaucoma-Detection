A Fast and Fully Automated System for Glaucoma Detection
This repository contains the conceptual framework and information for a deep learning-based system designed for the fast and fully automated detection of glaucoma from color fundus photographs. The project's goal is to provide a computationally light and memory-efficient solution suitable for integration into resource-limited devices like portable fundus cameras.




Overview
Glaucoma is a leading cause of irreversible blindness , often progressing without early symptoms. Early screening and diagnosis are crucial to saving vision. This project addresses this need by creating a fully automated system that analyzes fundus images to identify signs of glaucoma , demonstrating performance comparable to or exceeding state-of-the-art methods while significantly reducing resource requirements.





Key Features

Fully Automated: The system requires no manual cropping of the optic disc region, unlike many traditional methods.



High Efficiency: The proposed system requires 12 times less memory and produces decisions 2 times faster than a standard ResNet50 model.




High Accuracy: Achieves a 97.4% accuracy in distinguishing between 'glaucomatous' and 'non-glaucomatous' images.



Custom Architecture: Proposes a simplified, context-aware version of the YOLO Nano architecture for improved performance in optic disc detection.




Extensive Validation: The models were trained and evaluated on a large-scale dataset of 6,671 fundus images from seven publicly available sources.



Methodology
The system operates using a two-step deep learning pipeline:



Optic Disc (OD) Detection: An input color fundus photograph is first processed by a simplified YOLO network to automatically detect and locate the optic nerve head (ONH) region. This ensures the classification model focuses only on the most relevant part of the image.





Glaucoma Classification: The cropped ONH region is then fed into a MobileNetV3Small Convolutional Neural Network (CNN). This model classifies the region as either 'glaucomatous' or 'non-glaucomatous'.


Performance Metrics
The final system achieved the following performance:


Accuracy: 97.4% 


F1 Score: 97.3% 


Sensitivity: 97.5% 


Specificity: 97.2% 


Area Under the Curve (AUC): 99.3% 

Technology Stack

Programming Language: Python (v3.8.12) 


Deep Learning Frameworks: Keras (v2.4.3) , TensorFlow (v2.3.0) , PyTorch (v2.0.0) 

Key Models & Architectures:


Detection: YOLO Nano , YOLO-v5 Nano , YOLO-v7 Tiny 




Classification: MobileNetV2 , MobileNetV3Small , ResNet50 , Inception V3 , InceptionResNetV2 , 18-Layer CNN , Custom ResNet 


Dataset
The experiments were conducted using a total of 6,671 images from seven publicly available glaucoma datasets:


LAG 



ACRIMA 



Drishti-GS 



HRF 



RIM-ONE r2 



sjchoi86 HRF 



DRIONS-DB 


